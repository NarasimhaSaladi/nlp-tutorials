{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">NLP Tutorial:Text Classification USing Gensim Word Embeddings</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXLaHWbcL1Xv"
   },
   "source": [
    "Load Google News Word2vec model from gensim library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ukyzNAyBaPw",
    "outputId": "1ff883a7-ac8f-458c-f41f-aa1e2c81eb20"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m wv \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword2vec-google-news-300\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\downloader.py:503\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    501\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, BASE_DIR)\n\u001b[0;32m    502\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28m__import__\u001b[39m(name)\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~/gensim-data\\word2vec-google-news-300\\__init__.py:8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m():\n\u001b[0;32m      7\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword2vec-google-news-300\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword2vec-google-news-300.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2062\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit:\n\u001b[0;32m   2061\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(vocab_size, limit)\n\u001b[1;32m-> 2062\u001b[0m kv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[0;32m   2065\u001b[0m     _word2vec_read_binary(\n\u001b[0;32m   2066\u001b[0m         fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding\n\u001b[0;32m   2067\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:245\u001b[0m, in \u001b[0;36mKeyedVectors.__init__\u001b[1;34m(self, vector_size, count, dtype, mapfile_path)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# pointer to where next new entry will land\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_to_index \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m=\u001b[39m \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# formerly known as syn0\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# \"expandos\" are extra attributes stored for each key: {attribute_name} => numpy array of values of\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# this attribute, with one array value for each vector key.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# The same information used to be stored in a structure called Vocab in Gensim <4.0.0, but\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# with different indexing: {vector key} => Vocab object containing all attributes for the given vector key.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Don't modify expandos directly; call set_vecattr()/get_vecattr() instead.\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOR83YfLJRXG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729151"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_great = wv[\"great\"]\n",
    "wv_good = wv[\"good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (300,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_great.shape, wv_good.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDNq8C5rMEI2"
   },
   "source": [
    "### **Fake vs Real News Classification Using This Word2Vec Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n8FcENNMNYU"
   },
   "source": [
    "- Fake news refers to misinformation or disinformation in the country which is spread through word of mouth and more recently through digital communication such as What's app messages, social media posts, etc.\n",
    "\n",
    "- Fake news spreads faster than real news and creates problems and fear among groups and in society.\n",
    "\n",
    "- We are going to address these problems using classical NLP techniques and going to classify whether a given message/ text is **Real or Fake Message**.\n",
    "\n",
    "- We will use **glove embeddings** from spacy which is trained on massive wikipedia dataset to pre-process and text vectorization and apply different classification algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21PuUZq9MPhu"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Text\n",
    "        - label\n",
    "- Text is the statements or messages regarding a particular event/situation.\n",
    "\n",
    "- label feature tells whether the given text is Fake or Real.\n",
    "\n",
    "- As there are only 2 classes, this problem comes under the **Binary Classification.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "H3ij_XmtBaKP",
    "outputId": "948a24d6-c0fb-45ae-a581-f9545da1a318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake\n",
       "1  U.S. conservative leader optimistic of common ...  Real\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#read the dataset with name \"Fake_Real_Data.csv\" and store it in a variable df\n",
    "df = pd.read_csv(\"fake_and_real_news.csv\")\n",
    "\n",
    "#print the shape of dataframe\n",
    "print(df.shape)\n",
    "\n",
    "#print top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "upvt0Y63DLdt",
    "outputId": "86e66b38-7132-4ac6-9e8f-440a6c74ffa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Fake    5000\n",
       "Real    4900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of labels \n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3FuwvuFCBaNY",
    "outputId": "cae80a0f-e2de-4944-d3aa-8d59ca014cf9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0\n",
       "1  U.S. conservative leader optimistic of common ...  Real          1\n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1\n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0\n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add the new column which gives a unique number to each of these labels \n",
    "\n",
    "df['label_num'] = df['label'].map({'Fake' : 0, 'Real': 1})\n",
    "\n",
    "#check the results with top 5 rows\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will convert the text into a vector using gensim's word2vec embeddings. \n",
    "#### We will do this in three steps,\n",
    "\n",
    "1. Preprocess the text to remove stop words, punctuations and get lemma for each word\n",
    "2. Get word vectors for each of the words in a pre-processed sentece\n",
    "3. Take a mean of all word vectors to derive the numeric representation of the entire news article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's explore get_mean_vector api of gensim to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m r1 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean([wv_good, wv_great],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "r1 = np.mean([wv_good, wv_great],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04052734,  0.0625    , -0.01745605,  0.07861328,  0.03271484],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_good[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07177734,  0.20800781, -0.02844238,  0.17871094,  0.1328125 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_great[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05615234,  0.1352539 , -0.02294922,  0.12866211,  0.08276367],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = wv.get_mean_vector([\"good\", \"great\"],pre_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05615234,  0.1352539 , -0.02294922,  0.12866211,  0.08276367],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ged-kUXTIdq5"
   },
   "source": [
    "Now let's write the function that can do preprocessing and vectorization both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "5-CdpAtmIbjQ"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 588. MiB for an array with shape (154247100,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_lg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# if this fails then run \"python -m spacy download en_core_web_lg\" to download that model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_and_vectorize\u001b[39m(text):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# remove stop words and lemmatize the text\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     doc \u001b[38;5;241m=\u001b[39m nlp(text)\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:501\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(name)\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\en_core_web_lg\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_init_py\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:682\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE052\u001b[38;5;241m.\u001b[39mformat(path\u001b[38;5;241m=\u001b[39mdata_path))\n\u001b[1;32m--> 682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:547\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    538\u001b[0m config \u001b[38;5;241m=\u001b[39m load_config(config_path, overrides\u001b[38;5;241m=\u001b[39moverrides)\n\u001b[0;32m    539\u001b[0m nlp \u001b[38;5;241m=\u001b[39m load_model_from_config(\n\u001b[0;32m    540\u001b[0m     config,\n\u001b[0;32m    541\u001b[0m     vocab\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m     meta\u001b[38;5;241m=\u001b[39mmeta,\n\u001b[0;32m    546\u001b[0m )\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:2184\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[1;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[0;32m   2181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m   2182\u001b[0m     \u001b[38;5;66;03m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m     exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(exclude) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2184\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserializers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m path  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   2186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_link_components()\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:1372\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[1;32m-> 1372\u001b[0m         \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\language.py:2160\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m   2158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize_vocab\u001b[39m(path: Path) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m-> 2160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\vocab.pyx:513\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\vectors.pyx:718\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:1372\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, reader \u001b[38;5;129;01min\u001b[39;00m readers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   1370\u001b[0m     \u001b[38;5;66;03m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude:\n\u001b[1;32m-> 1372\u001b[0m         \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\vectors.pyx:703\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk.load_vectors\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\naras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 588. MiB for an array with shape (154247100,) and data type float32"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\") # if this fails then run \"python -m spacy download en_core_web_lg\" to download that model\n",
    "\n",
    "def preprocess_and_vectorize(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = preprocess_and_vectorize(\"Don't worry if you don't understand\")\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOke8KXkIbmE"
   },
   "outputs": [],
   "source": [
    "#this query takes few minutes, so go get some walk :)\n",
    "\n",
    "df['vector'] = df['Text'].apply(lambda text: preprocess_and_vectorize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m] \n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['vector'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jI5EobDLQE_o",
    "outputId": "69737b13-3fe3-43f7-ca4e-eddbf50da1b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top Trump Surrogate BRUTALLY Stabs Him In The...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.008145372, 0.019952843, -0.00989356, 0.0344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. conservative leader optimistic of common ...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.00861828, 0.007408227, 0.0007675802, 0.0138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump proposes U.S. tax overhaul, stirs concer...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.01823076, 0.0063306373, -0.0058634086, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Court Forces Ohio To Allow Millions Of Illega...</td>\n",
       "      <td>Fake</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.012453172, 0.0122098895, 6.3027373e-06, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrats say Trump agrees to work on immigrat...</td>\n",
       "      <td>Real</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0022669104, 0.011340516, 0.003596399, 0.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text label  label_num  \\\n",
       "0   Top Trump Surrogate BRUTALLY Stabs Him In The...  Fake          0   \n",
       "1  U.S. conservative leader optimistic of common ...  Real          1   \n",
       "2  Trump proposes U.S. tax overhaul, stirs concer...  Real          1   \n",
       "3   Court Forces Ohio To Allow Millions Of Illega...  Fake          0   \n",
       "4  Democrats say Trump agrees to work on immigrat...  Real          1   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.008145372, 0.019952843, -0.00989356, 0.0344...  \n",
       "1  [0.00861828, 0.007408227, 0.0007675802, 0.0138...  \n",
       "2  [0.01823076, 0.0063306373, -0.0058634086, 0.03...  \n",
       "3  [0.012453172, 0.0122098895, 6.3027373e-06, 0.0...  \n",
       "4  [-0.0022669104, 0.011340516, 0.003596399, 0.02...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2XGariWM09j"
   },
   "source": [
    "**Train-Test splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJfmmbxBDYuO"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.vector.values, \n",
    "    df.label_num, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=df.label_num\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08-oivPtM8a5"
   },
   "source": [
    "**Reshaping the X_train and X_test so as to fit for models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOOO4prQi7hg",
    "outputId": "ea31fc23-a63b-42ff-fef5-6e21c038b733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train before reshaping:  (7920,)\n",
      "Shape of X_test before reshaping:  (1980,)\n",
      "Shape of X_train after reshaping:  (7920, 300)\n",
      "Shape of X_test after reshaping:  (1980, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train before reshaping: \", X_train.shape)\n",
    "print(\"Shape of X_test before reshaping: \", X_test.shape)\n",
    "\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d =  np.stack(X_test)\n",
    "\n",
    "print(\"Shape of X_train after reshaping: \", X_train_2d.shape)\n",
    "print(\"Shape of X_test after reshaping: \", X_test_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5HmfA2gRyQY"
   },
   "source": [
    "**Train Machine Learning Model**\n",
    "\n",
    "I tried Random forest, decision tree, naive bayes etc classifiers as well but gradient boosting gave the best performance of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Q8Sy2iENZr7",
    "outputId": "159d92d5-17bd-4c18-c797-ed049b6db0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1000\n",
      "           1       0.97      0.98      0.98       980\n",
      "\n",
      "    accuracy                           0.98      1980\n",
      "   macro avg       0.98      0.98      0.98      1980\n",
      "weighted avg       0.98      0.98      0.98      1980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make some predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_news = [\n",
    "    \"Michigan governor denies misleading U.S. House on Flint water (Reuters) - Michigan Governor Rick Snyder denied Thursday that he had misled a U.S. House of Representatives committee last year over testimony on Flintâ€™s water crisis after lawmakers asked if his testimony had been contradicted by a witness in a court hearing. The House Oversight and Government Reform Committee wrote Snyder earlier Thursday asking him about published reports that one of his aides, Harvey Hollins, testified in a court hearing last week in Michigan that he had notified Snyder of an outbreak of Legionnairesâ€™ disease linked to the Flint water crisis in December 2015, rather than 2016 as Snyder had testified. â€œMy testimony was truthful and I stand by it,â€ Snyder told the committee in a letter, adding that his office has provided tens of thousands of pages of records to the committee and would continue to cooperate fully.  Last week, prosecutors in Michigan said Dr. Eden Wells, the stateâ€™s chief medical executive who already faced lesser charges, would become the sixth current or former official to face involuntary manslaughter charges in connection with the crisis. The charges stem from more than 80 cases of Legionnairesâ€™ disease and at least 12 deaths that were believed to be linked to the water in Flint after the city switched its source from Lake Huron to the Flint River in April 2014. Wells was among six current and former Michigan and Flint officials charged in June. The other five, including Michigan Health and Human Services Director Nick Lyon, were charged at the time with involuntary manslaughter\",\n",
    "    \" WATCH: Fox News Host Loses Her Sh*t, Says Investigating Russia For Hacking Our Election Is Unpatriotic This woman is insane.In an incredibly disrespectful rant against President Obama and anyone else who supports investigating Russian interference in our election, Fox News host Jeanine Pirro said that anybody who is against Donald Trump is anti-American. Look, it s time to take sides,  she began.\",\n",
    "    \" Sarah Palin Celebrates After White Man Who Pulled Gun On Black Protesters Goes Unpunished (VIDEO) Sarah Palin, one of the nigh-innumerable  deplorables  in Donald Trump s  basket,  almost outdid herself in terms of horribleness on Friday.\"\n",
    "]\n",
    "\n",
    "test_news_vectors = [preprocess_and_vectorize(n) for n in test_news]\n",
    "clf.predict(test_news_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppttUIGMNzk7"
   },
   "source": [
    "**Confusion Matrix for Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "TfjngBUSBaYC",
    "outputId": "8aa7e3f1-0f37-47cb-bdd3-022fc5e10091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#finally print the confusion matrix for the best model (GradientBoostingClassifier)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Truth')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
